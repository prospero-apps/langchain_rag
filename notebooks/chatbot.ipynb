{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df8f91db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Using cached langchain-1.0.3-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting langchain-text-splitters\n",
      "  Using cached langchain_text_splitters-1.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting langchain-community\n",
      "  Using cached langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting bs4\n",
      "  Using cached bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
      "Collecting langchain-core<2.0.0,>=1.0.0 (from langchain)\n",
      "  Using cached langchain_core-1.0.3-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting langgraph<1.1.0,>=1.0.2 (from langchain)\n",
      "  Using cached langgraph-1.0.2-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Using cached pydantic-2.12.3-py3-none-any.whl.metadata (87 kB)\n",
      "Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain-community)\n",
      "  Using cached langchain_classic-1.0.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting SQLAlchemy<3.0.0,>=1.4.0 (from langchain-community)\n",
      "  Downloading sqlalchemy-2.0.44-cp312-cp312-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting requests<3.0.0,>=2.32.5 (from langchain-community)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting PyYAML<7.0.0,>=5.3.0 (from langchain-community)\n",
      "  Using cached pyyaml-6.0.3-cp312-cp312-win_amd64.whl.metadata (2.4 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain-community)\n",
      "  Downloading aiohttp-3.13.2-cp312-cp312-win_amd64.whl.metadata (8.4 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-community)\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.10.1 (from langchain-community)\n",
      "  Using cached pydantic_settings-2.11.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting langsmith<1.0.0,>=0.1.125 (from langchain-community)\n",
      "  Using cached langsmith-0.4.40-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Using cached httpx_sse-0.4.3-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting numpy>=1.26.2 (from langchain-community)\n",
      "  Downloading numpy-2.3.4-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "     ---------------------------------------- 0.0/60.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/60.9 kB ? eta -:--:--\n",
      "     ------ --------------------------------- 10.2/60.9 kB ? eta -:--:--\n",
      "     ------------------- ------------------ 30.7/60.9 kB 220.2 kB/s eta 0:00:01\n",
      "     ------------------- ------------------ 30.7/60.9 kB 220.2 kB/s eta 0:00:01\n",
      "     ------------------------- ------------ 41.0/60.9 kB 196.9 kB/s eta 0:00:01\n",
      "     -------------------------------------- 60.9/60.9 kB 232.5 kB/s eta 0:00:00\n",
      "Collecting beautifulsoup4 (from bs4)\n",
      "  Using cached beautifulsoup4-4.14.2-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached frozenlist-1.8.0-cp312-cp312-win_amd64.whl.metadata (21 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached multidict-6.7.0-cp312-cp312-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading propcache-0.4.1-cp312-cp312-win_amd64.whl.metadata (14 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached yarl-1.22.0-cp312-cp312-win_amd64.whl.metadata (77 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
      "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting jsonpatch<2.0.0,>=1.33.0 (from langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (25.0)\n",
      "Collecting typing-extensions<5.0.0,>=4.7.0 (from langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph<1.1.0,>=1.0.2->langchain)\n",
      "  Using cached langgraph_checkpoint-3.0.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langgraph-prebuilt<1.1.0,>=1.0.2 (from langgraph<1.1.0,>=1.0.2->langchain)\n",
      "  Using cached langgraph_prebuilt-1.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph<1.1.0,>=1.0.2->langchain)\n",
      "  Using cached langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting xxhash>=3.5.0 (from langgraph<1.1.0,>=1.0.2->langchain)\n",
      "  Using cached xxhash-3.6.0-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith<1.0.0,>=0.1.125->langchain-community)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson>=3.9.14 (from langsmith<1.0.0,>=0.1.125->langchain-community)\n",
      "  Downloading orjson-3.11.4-cp312-cp312-win_amd64.whl.metadata (42 kB)\n",
      "     ---------------------------------------- 0.0/42.9 kB ? eta -:--:--\n",
      "     -------------------------------------- - 41.0/42.9 kB 2.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 42.9/42.9 kB 1.1 MB/s eta 0:00:00\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith<1.0.0,>=0.1.125->langchain-community)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard>=0.23.0 (from langsmith<1.0.0,>=0.1.125->langchain-community)\n",
      "  Using cached zstandard-0.25.0-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.4 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached pydantic_core-2.41.4-cp312-cp312-win_amd64.whl.metadata (7.4 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.10.1->langchain-community)\n",
      "  Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests<3.0.0,>=2.32.5->langchain-community)\n",
      "  Using cached charset_normalizer-3.4.4-cp312-cp312-win_amd64.whl.metadata (38 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3.0.0,>=2.32.5->langchain-community)\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3.0.0,>=2.32.5->langchain-community)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3.0.0,>=2.32.5->langchain-community)\n",
      "  Using cached certifi-2025.10.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting greenlet>=1 (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community)\n",
      "  Using cached greenlet-3.2.4-cp312-cp312-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->bs4)\n",
      "  Using cached soupsieve-2.8-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting anyio (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community)\n",
      "  Using cached anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain)\n",
      "  Using cached ormsgpack-1.11.0-cp312-cp312-win_amd64.whl.metadata (1.2 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
      "  Using cached mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Using cached langchain-1.0.3-py3-none-any.whl (91 kB)\n",
      "Using cached langchain_text_splitters-1.0.0-py3-none-any.whl (33 kB)\n",
      "Using cached langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
      "Using cached bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
      "Downloading aiohttp-3.13.2-cp312-cp312-win_amd64.whl (453 kB)\n",
      "   ---------------------------------------- 0.0/453.5 kB ? eta -:--:--\n",
      "   --- ----------------------------------- 41.0/453.5 kB 991.0 kB/s eta 0:00:01\n",
      "   -------- ------------------------------- 92.2/453.5 kB 1.3 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 92.2/453.5 kB 1.3 MB/s eta 0:00:01\n",
      "   -------- ----------------------------- 102.4/453.5 kB 535.8 kB/s eta 0:00:01\n",
      "   --------------- ---------------------- 184.3/453.5 kB 743.9 kB/s eta 0:00:01\n",
      "   ------------------------- -------------- 286.7/453.5 kB 1.0 MB/s eta 0:00:01\n",
      "   ------------------------- ------------ 307.2/453.5 kB 999.9 kB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 389.1/453.5 kB 1.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 453.5/453.5 kB 1.1 MB/s eta 0:00:00\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached httpx_sse-0.4.3-py3-none-any.whl (9.0 kB)\n",
      "Using cached langchain_classic-1.0.0-py3-none-any.whl (1.0 MB)\n",
      "Using cached langchain_core-1.0.3-py3-none-any.whl (469 kB)\n",
      "Using cached langgraph-1.0.2-py3-none-any.whl (156 kB)\n",
      "Using cached langsmith-0.4.40-py3-none-any.whl (399 kB)\n",
      "Downloading numpy-2.3.4-cp312-cp312-win_amd64.whl (12.8 MB)\n",
      "   ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.8 MB 8.9 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 0.6/12.8 MB 7.0 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 0.6/12.8 MB 7.0 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 0.6/12.8 MB 3.2 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 1.0/12.8 MB 4.3 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 1.5/12.8 MB 5.3 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.7/12.8 MB 5.6 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.7/12.8 MB 4.9 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 2.1/12.8 MB 5.4 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 3.2/12.8 MB 7.0 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 3.2/12.8 MB 6.8 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 3.8/12.8 MB 6.7 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 5.4/12.8 MB 8.9 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 6.3/12.8 MB 9.8 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 6.4/12.8 MB 9.3 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 8.6/12.8 MB 11.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 11.0/12.8 MB 17.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 12.0/12.8 MB 23.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 12.0/12.8 MB 23.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 12.0/12.8 MB 23.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 12.0/12.8 MB 23.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.3/12.8 MB 15.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.8/12.8 MB 16.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.8/12.8 MB 14.5 MB/s eta 0:00:00\n",
      "Using cached pydantic-2.12.3-py3-none-any.whl (462 kB)\n",
      "Using cached pydantic_core-2.41.4-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "Using cached pydantic_settings-2.11.0-py3-none-any.whl (48 kB)\n",
      "Using cached pyyaml-6.0.3-cp312-cp312-win_amd64.whl (154 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading sqlalchemy-2.0.44-cp312-cp312-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------  2.1/2.1 MB 66.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 33.7 MB/s eta 0:00:00\n",
      "Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Using cached beautifulsoup4-4.14.2-py3-none-any.whl (106 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Using cached certifi-2025.10.5-py3-none-any.whl (163 kB)\n",
      "Using cached charset_normalizer-3.4.4-cp312-cp312-win_amd64.whl (107 kB)\n",
      "Downloading frozenlist-1.8.0-cp312-cp312-win_amd64.whl (44 kB)\n",
      "   ---------------------------------------- 0.0/44.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 44.6/44.6 kB 2.1 MB/s eta 0:00:00\n",
      "Using cached greenlet-3.2.4-cp312-cp312-win_amd64.whl (299 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached langgraph_checkpoint-3.0.0-py3-none-any.whl (46 kB)\n",
      "Using cached langgraph_prebuilt-1.0.2-py3-none-any.whl (34 kB)\n",
      "Using cached langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
      "Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading multidict-6.7.0-cp312-cp312-win_amd64.whl (46 kB)\n",
      "   ---------------------------------------- 0.0/46.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 46.1/46.1 kB ? eta 0:00:00\n",
      "Downloading orjson-3.11.4-cp312-cp312-win_amd64.whl (131 kB)\n",
      "   ---------------------------------------- 0.0/131.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 131.5/131.5 kB 3.8 MB/s eta 0:00:00\n",
      "Downloading propcache-0.4.1-cp312-cp312-win_amd64.whl (41 kB)\n",
      "   ---------------------------------------- 0.0/41.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 41.7/41.7 kB 2.0 MB/s eta 0:00:00\n",
      "Downloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached soupsieve-2.8-py3-none-any.whl (36 kB)\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached xxhash-3.6.0-cp312-cp312-win_amd64.whl (31 kB)\n",
      "Downloading yarl-1.22.0-cp312-cp312-win_amd64.whl (87 kB)\n",
      "   ---------------------------------------- 0.0/87.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 87.2/87.2 kB 5.1 MB/s eta 0:00:00\n",
      "Using cached zstandard-0.25.0-cp312-cp312-win_amd64.whl (506 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Using cached ormsgpack-1.11.0-cp312-cp312-win_amd64.whl (112 kB)\n",
      "Using cached anyio-4.11.0-py3-none-any.whl (109 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: zstandard, xxhash, urllib3, typing-extensions, tenacity, soupsieve, sniffio, PyYAML, python-dotenv, propcache, ormsgpack, orjson, numpy, mypy-extensions, multidict, marshmallow, jsonpointer, idna, httpx-sse, h11, greenlet, frozenlist, charset_normalizer, certifi, attrs, annotated-types, aiohappyeyeballs, yarl, typing-inspection, typing-inspect, SQLAlchemy, requests, pydantic-core, jsonpatch, httpcore, beautifulsoup4, anyio, aiosignal, requests-toolbelt, pydantic, httpx, dataclasses-json, bs4, aiohttp, pydantic-settings, langsmith, langgraph-sdk, langchain-core, langgraph-checkpoint, langchain-text-splitters, langgraph-prebuilt, langchain-classic, langgraph, langchain-community, langchain\n",
      "Successfully installed PyYAML-6.0.3 SQLAlchemy-2.0.44 aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 annotated-types-0.7.0 anyio-4.11.0 attrs-25.4.0 beautifulsoup4-4.14.2 bs4-0.0.2 certifi-2025.10.5 charset_normalizer-3.4.4 dataclasses-json-0.6.7 frozenlist-1.8.0 greenlet-3.2.4 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 httpx-sse-0.4.3 idna-3.11 jsonpatch-1.33 jsonpointer-3.0.0 langchain-1.0.3 langchain-classic-1.0.0 langchain-community-0.4.1 langchain-core-1.0.3 langchain-text-splitters-1.0.0 langgraph-1.0.2 langgraph-checkpoint-3.0.0 langgraph-prebuilt-1.0.2 langgraph-sdk-0.2.9 langsmith-0.4.40 marshmallow-3.26.1 multidict-6.7.0 mypy-extensions-1.1.0 numpy-2.3.4 orjson-3.11.4 ormsgpack-1.11.0 propcache-0.4.1 pydantic-2.12.3 pydantic-core-2.41.4 pydantic-settings-2.11.0 python-dotenv-1.2.1 requests-2.32.5 requests-toolbelt-1.0.0 sniffio-1.3.1 soupsieve-2.8 tenacity-9.1.2 typing-extensions-4.15.0 typing-inspect-0.9.0 typing-inspection-0.4.2 urllib3-2.5.0 xxhash-3.6.0 yarl-1.22.0 zstandard-0.25.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain-text-splitters langchain-community bs4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9da313e",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f89cb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fa33599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain[openai] in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (1.0.3)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from langchain[openai]) (1.0.3)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from langchain[openai]) (1.0.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from langchain[openai]) (2.12.3)\n",
      "Collecting langchain-openai (from langchain[openai])\n",
      "  Using cached langchain_openai-1.0.2-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain[openai]) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain[openai]) (0.4.40)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain[openai]) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain[openai]) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain[openai]) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain[openai]) (4.15.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain[openai]) (3.0.0)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain[openai]) (1.0.2)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain[openai]) (0.2.9)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain[openai]) (3.6.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain[openai]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain[openai]) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain[openai]) (0.4.2)\n",
      "Collecting openai<3.0.0,>=1.109.1 (from langchain-openai->langchain[openai])\n",
      "  Using cached openai-2.7.1-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting tiktoken<1.0.0,>=0.7.0 (from langchain-openai->langchain[openai])\n",
      "  Using cached tiktoken-0.12.0-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain[openai]) (3.0.0)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain[openai]) (1.11.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain[openai]) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain[openai]) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain[openai]) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain[openai]) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain[openai]) (0.25.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai->langchain[openai]) (4.11.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai<3.0.0,>=1.109.1->langchain-openai->langchain[openai])\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.10.0 (from openai<3.0.0,>=1.109.1->langchain-openai->langchain[openai])\n",
      "  Using cached jiter-0.11.1-cp312-cp312-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: sniffio in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai->langchain[openai]) (1.3.1)\n",
      "Collecting tqdm>4 (from openai<3.0.0,>=1.109.1->langchain-openai->langchain[openai])\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1.0.0,>=0.7.0->langchain-openai->langchain[openai])\n",
      "  Using cached regex-2025.11.3-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai<3.0.0,>=1.109.1->langchain-openai->langchain[openai]) (3.11)\n",
      "Requirement already satisfied: certifi in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain[openai]) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain[openai]) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain[openai]) (0.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain[openai]) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain[openai]) (2.5.0)\n",
      "Requirement already satisfied: colorama in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from tqdm>4->openai<3.0.0,>=1.109.1->langchain-openai->langchain[openai]) (0.4.6)\n",
      "Using cached langchain_openai-1.0.2-py3-none-any.whl (81 kB)\n",
      "Using cached openai-2.7.1-py3-none-any.whl (1.0 MB)\n",
      "Using cached tiktoken-0.12.0-cp312-cp312-win_amd64.whl (878 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached jiter-0.11.1-cp312-cp312-win_amd64.whl (204 kB)\n",
      "Using cached regex-2025.11.3-cp312-cp312-win_amd64.whl (277 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, regex, jiter, distro, tiktoken, openai, langchain-openai\n",
      "Successfully installed distro-1.9.0 jiter-0.11.1 langchain-openai-1.0.2 openai-2.7.1 regex-2025.11.3 tiktoken-0.12.0 tqdm-4.67.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -U \"langchain[openai]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bd48a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "model = init_chat_model(\"gpt-4.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a52a127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-openai in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.2 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from langchain-openai) (1.0.3)\n",
      "Requirement already satisfied: openai<3.0.0,>=1.109.1 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from langchain-openai) (2.7.1)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (0.4.40)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (25.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (2.12.3)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (4.15.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.11.1)\n",
      "Requirement already satisfied: sniffio in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.32.5)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai<3.0.0,>=1.109.1->langchain-openai) (3.11)\n",
      "Requirement already satisfied: certifi in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.2->langchain-openai) (3.0.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai) (0.25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.2->langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.2->langchain-openai) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.2->langchain-openai) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.5.0)\n",
      "Requirement already satisfied: colorama in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from tqdm>4->openai<3.0.0,>=1.109.1->langchain-openai) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -U \"langchain-openai\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36e70e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a087adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-core in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (1.0.3)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from langchain-core) (0.4.40)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from langchain-core) (25.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from langchain-core) (2.12.3)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from langchain-core) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from langchain-core) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from langchain-core) (4.15.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.4.2)\n",
      "Requirement already satisfied: anyio in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (4.11.0)\n",
      "Requirement already satisfied: certifi in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.9)\n",
      "Requirement already satisfied: idna in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (0.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in d:\\projects\\langchain_rag_pdf\\venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (1.3.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -U \"langchain-core\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88004e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "vector_store = InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d360bf",
   "metadata": {},
   "source": [
    "## Document Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "677dee80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf\n",
      "  Using cached pypdf-6.1.3-py3-none-any.whl.metadata (7.1 kB)\n",
      "Using cached pypdf-6.1.3-py3-none-any.whl (323 kB)\n",
      "Installing collected packages: pypdf\n",
      "Successfully installed pypdf-6.1.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f349e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# Get the absolute path to the PDF file\n",
    "pdf_path = os.path.join(os.path.dirname(os.getcwd()), \"docs\", \"AEM1.pdf\")\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5bbed85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of pages loaded (the PDF has 43 pages)\n",
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33c4f476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prosperoenglish.com www.youtube.com/c/ProsperoEnglish \n",
      " \n",
      "3 Your American English Magazine | 1/2022 \n",
      " \n",
      "Editor’s Letter \n",
      "Hey there, I’m excited to deliver this very first \n",
      "issue of Your American English Magazine to you. I \n",
      "don’t know how this new magazine will be doing. \n",
      "Hopefully well, because if there is interest in it, I’ll \n",
      "be publishing more issues on a regular basis. \n",
      "So, what will you find in this issue? First, there’s a \n",
      "story, A Winter Hike. I’m planning to write a story \n",
      "like that in eac\n"
     ]
    }
   ],
   "source": [
    "# Let's see the third page (Editor's Letter)\n",
    "page3 = pages[2]\n",
    "print(page3.page_content[:500])  # print the first 500 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00228ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': 'Microsoft® Office Word 2007',\n",
       " 'creator': 'Microsoft® Office Word 2007',\n",
       " 'creationdate': '2022-02-17T14:01:22+01:00',\n",
       " 'title': 'prosperoenglish.com',\n",
       " 'author': 'Victor',\n",
       " 'moddate': '2022-02-17T14:01:22+01:00',\n",
       " 'source': 'd:\\\\Projects\\\\langchain_RAG_PDF\\\\docs\\\\AEM1.pdf',\n",
       " 'total_pages': 43,\n",
       " 'page': 2,\n",
       " 'page_label': '3'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see the metadata of the third page\n",
    "page3.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d48987",
   "metadata": {},
   "source": [
    "## Document Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1daf538",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    add_start_index=True\n",
    ")\n",
    "\n",
    "docs = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38030345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of documents after splitting\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78c24e0",
   "metadata": {},
   "source": [
    "## Embedding and Storing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02bed22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n"
     ]
    }
   ],
   "source": [
    "doc_ids = vector_store.add_documents(documents=docs)\n",
    "print(len(doc_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8a57e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499d3d77-3c4d-40e2-92b4-68f00bdd7a77\n"
     ]
    }
   ],
   "source": [
    "print(doc_ids[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331ea57e",
   "metadata": {},
   "source": [
    "## RAG Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b4f432e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68300a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG agent\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve(query: str):\n",
    "    \"\"\"Retrieve information to help answer a query.\"\"\"\n",
    "    retrieved_docs = vector_store.similarity_search(query, k=2)\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\nContent: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return serialized, retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e0ac9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33e1b77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [retrieve]\n",
    "\n",
    "system_prompt = (\n",
    "    \"You have access to a tool that retrieves context from a PDF document. \"\n",
    "    \"Use it to better answer user queries.\"\n",
    ")\n",
    "\n",
    "agent = create_agent(model, tools, system_prompt=system_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82b41a2",
   "metadata": {},
   "source": [
    "## Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9539b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = (\n",
    "    \"Who are Frieda, Borg, Kev, Ike and Bree to one another?\\n\\n\"\n",
    "    \"How old are they?\\n\\n\"\n",
    "    \"What is the reason why Kev and Ike initially didn't go with their folks for a hike.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec2c53ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Who are Frieda, Borg, Kev, Ike and Bree to one another?\n",
      "\n",
      "How old are they?\n",
      "\n",
      "What is the reason why Kev and Ike initially didn't go with their folks for a hike.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (call_qgrc02mCuY14NQoRN9XVUOWy)\n",
      " Call ID: call_qgrc02mCuY14NQoRN9XVUOWy\n",
      "  Args:\n",
      "    query: Who are Frieda, Borg, Kev, Ike and Bree to one another?\n",
      "  retrieve (call_YBvPgsqdIsqKlTHSBwzKteDl)\n",
      " Call ID: call_YBvPgsqdIsqKlTHSBwzKteDl\n",
      "  Args:\n",
      "    query: How old are Frieda, Borg, Kev, Ike and Bree?\n",
      "  retrieve (call_nkUW6W6iBxemTxfEyrH76Sxy)\n",
      " Call ID: call_nkUW6W6iBxemTxfEyrH76Sxy\n",
      "  Args:\n",
      "    query: Why did Kev and Ike initially not go with their folks for a hike?\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2022-02-17T14:01:22+01:00', 'title': 'prosperoenglish.com', 'author': 'Victor', 'moddate': '2022-02-17T14:01:22+01:00', 'source': 'd:\\\\Projects\\\\langchain_RAG_PDF\\\\docs\\\\AEM1.pdf', 'total_pages': 43, 'page': 4, 'page_label': '5', 'start_index': 0}\n",
      "Content: prosperoenglish.com www.youtube.com/c/ProsperoEnglish \n",
      " \n",
      "5 Your American English Magazine | 1/2022 \n",
      " \n",
      "FRIEDA: You are so modest, sweetie. By the way, have \n",
      "you seen your daddy? \n",
      "I picked up the car from the repair shop. \n",
      "Pick the kids up from school. \n",
      " \n",
      "drive sb nuts - to make sb crazy \n",
      " \n",
      "sundown - the time when the sun goes below the \n",
      "horizon, sunset \n",
      "Let’s meet tomorrow at sundown. \n",
      " \n",
      " \n",
      "BREE: No, I have no idea where he could be.  \n",
      "FRIEDA: Ike and Kev are coming to pick us up. This man is \n",
      "driving me nuts. Where is he? \n",
      "Ike and Kev are Bree’s brothers. They didn’t go with them \n",
      "because Ike had to study for his math test and Kev wanted to \n",
      "visit his friend. But they promised they’d pick them all up \n",
      "before sundown.  \n",
      "By the way, Borg is 47 years old, Frieda is 46, Ike is 16, Kev is \n",
      "14 and Bree is 12. Just so that you know. \n",
      " \n",
      " \n",
      "snowmobile /ˈsnoʊmoʊˌbiːl/ - a vehicle used for \n",
      "traveling on snow or ice \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "get/find your bearings - to find out your position\n",
      "\n",
      "Source: {'producer': 'Microsoft® Office Word 2007', 'creator': 'Microsoft® Office Word 2007', 'creationdate': '2022-02-17T14:01:22+01:00', 'title': 'prosperoenglish.com', 'author': 'Victor', 'moddate': '2022-02-17T14:01:22+01:00', 'source': 'd:\\\\Projects\\\\langchain_RAG_PDF\\\\docs\\\\AEM1.pdf', 'total_pages': 43, 'page': 4, 'page_label': '5', 'start_index': 795}\n",
      "Content: 14 and Bree is 12. Just so that you know. \n",
      " \n",
      " \n",
      "snowmobile /ˈsnoʊmoʊˌbiːl/ - a vehicle used for \n",
      "traveling on snow or ice \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "get/find your bearings - to find out your position \n",
      "We had to find our bearings [= figure out exactly where we \n",
      "were] before we moved on. \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "tops - at the very most \n",
      "It will cost $5, tops. \n",
      "Ike and Kev are coming in their snowmobile. There’s a lot of \n",
      "snow everywhere.  \n",
      "IKE: It’s getting dark. We better hurry.  \n",
      "KEV:  Hey, Ike. Do you even know where we are? Let’s \n",
      "stop here and get our bearings. \n",
      "IKE: No, Kev, we don’t have to do that. I know exactly \n",
      "where we are.  \n",
      "KEV: So, how much farther? \n",
      "IKE: Five minutes, tops. \n",
      "WILL in reported speech \n",
      "In reported speech WILL is replaced by WOULD: \n",
      "direct speech: \n",
      "He said: ‘I will do that.’ \n",
      " \n",
      "reported speech: \n",
      "He said he would do that. \n",
      "BETTER \n",
      "BETTER is often used instead of HAD BETTER  \n",
      "or ‘D BETTER, so: \n",
      "You better go. \n",
      "= You’d better go. \n",
      "= You had better go.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Here are the answers to your questions:\n",
      "\n",
      "1. Relationships:\n",
      "   - Borg and Frieda are the parents.\n",
      "   - Ike, Kev, and Bree are their children.\n",
      "   - Specifically: Ike and Kev are Bree’s brothers.\n",
      "\n",
      "2. Ages:\n",
      "   - Borg: 47 years old\n",
      "   - Frieda: 46 years old\n",
      "   - Ike: 16 years old\n",
      "   - Kev: 14 years old\n",
      "   - Bree: 12 years old\n",
      "\n",
      "3. Why Kev and Ike initially didn’t go with their folks for a hike:\n",
      "   - Ike had to study for his math test.\n",
      "   - Kev wanted to visit his friend.\n",
      "\n",
      "They promised, however, that they would pick everyone up before sundown.\n"
     ]
    }
   ],
   "source": [
    "for event in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": query}]},\n",
    "    stream_mode=\"values\"\n",
    "):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
